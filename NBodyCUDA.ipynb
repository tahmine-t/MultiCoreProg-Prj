{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcba5QZoc_pA"
      },
      "source": [
        "# Check NVIDIA CUDA Compiler Version\n",
        "This cell runs the command !nvcc --version to check the version of the NVIDIA CUDA Compiler (nvcc) installed in the environment. The CUDA Compiler is part of the NVIDIA CUDA Toolkit and is essential for compiling CUDA programs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZeANr2tH7mMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c04986-20b4-4e5d-b9fe-0b9831a0ea03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E21dZhJmdPr8"
      },
      "source": [
        "# Check GCC Version\n",
        "This cell runs !gcc --version to display the installed version of the GNU Compiler Collection (GCC).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YnL1lWlN1BEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c734bc0-bc40-4382-f3d2-e273b86ba4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajhb7DMseQ1I"
      },
      "source": [
        "# Install and Load NVCC4Jupyter\n",
        "This cell installs the nvcc4jupyter package and loads the NVCC extension for Jupyter notebooks. The commands are:\n",
        "\n",
        "\n",
        "*   !pip install nvcc4jupyter: Installs the nvcc4jupyter package, which allows you to write and run CUDA C/C++ code directly in Jupyter notebooks.\n",
        "\n",
        "*   %load_ext nvcc4jupyter: Loads the NVCC extension to enable the execution of CUDA code within notebook cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zAArg9nieuZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f6601b-d998-4b92-ac3b-8ca12d6dc4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpl7tp5x40\".\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsjLUp_ydw8d"
      },
      "source": [
        "# List NVIDIA GPUs\n",
        "This cell runs the command !nvidia-smi -L to list all NVIDIA GPUs available in the environment. The nvidia-smi (NVIDIA System Management Interface) tool provides information about the NVIDIA driver and hardware, including the GPU model, memory, and other specifications. This command is useful for confirming the presence and details of GPU resources available for your computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LHhK0AxJduGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9f41be-ab9e-4fec-a973-6b0c71a638a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-e550199c-f636-1411-95f9-fe246481c385)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGehaasna1L0"
      },
      "source": [
        "# Display GPU Properties with CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xHrsi9Nhuju",
        "outputId": "e9bcf96b-9e38-4260-a518-f7c598ef973c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0\n",
            "Device Name: Tesla T4\n",
            "Total Global Memory: 14.75 GB\n",
            "Shared Memory per Block: 48.00 KB\n",
            "Registers per Block: 65536\n",
            "Warp Size: 32\n",
            "Max Threads per Block: 1024\n",
            "Max Threads per Multi-Processor: 1024\n",
            "Max Grid Dimensions: [2147483647, 65535, 65535]\n",
            "Max Block Dimensions: [1024, 1024, 64]\n",
            "Compute Capability: 7.5\n",
            "Multi-Processor Count: 40\n",
            "Max Texture 1D Size: 131072\n",
            "Max Texture 2D Size: [131072, 65536]\n",
            "Concurrent Kernels: Supported\n",
            "ECC Memory: Enabled\n",
            "\n",
            "Cache Configuration:\n",
            "L2 Cache Size: 4096.00 KB\n",
            "Global Memory Bus Width: 256 bits\n",
            "Memory Clock Rate: 5.00 GHz\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "// Convert bytes to gigabytes\n",
        "float bytesToGB(size_t bytes) {\n",
        "    return static_cast<float>(bytes) / (1024.0f * 1024.0f * 1024.0f);\n",
        "}\n",
        "\n",
        "// Convert bytes to kilobytes\n",
        "float bytesToKB(size_t bytes) {\n",
        "    return static_cast<float>(bytes) / 1024.0f;\n",
        "}\n",
        "\n",
        "void displayGPUProperties(const cudaDeviceProp& deviceProp) {\n",
        "    printf(\"Device Name: %s\\n\", deviceProp.name);\n",
        "    printf(\"Total Global Memory: %.2f GB\\n\", bytesToGB(deviceProp.totalGlobalMem));\n",
        "    printf(\"Shared Memory per Block: %.2f KB\\n\", static_cast<float>(deviceProp.sharedMemPerBlock) / 1024.0f);\n",
        "    printf(\"Registers per Block: %d\\n\", deviceProp.regsPerBlock);\n",
        "    printf(\"Warp Size: %d\\n\", deviceProp.warpSize);\n",
        "    printf(\"Max Threads per Block: %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "    printf(\"Max Threads per Multi-Processor: %d\\n\", deviceProp.maxThreadsPerMultiProcessor);\n",
        "    printf(\"Max Grid Dimensions: [%d, %d, %d]\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2]);\n",
        "    printf(\"Max Block Dimensions: [%d, %d, %d]\\n\", deviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n",
        "    printf(\"Compute Capability: %d.%d\\n\", deviceProp.major, deviceProp.minor);\n",
        "    printf(\"Multi-Processor Count: %d\\n\", deviceProp.multiProcessorCount);\n",
        "    printf(\"Max Texture 1D Size: %d\\n\", deviceProp.maxTexture1D);\n",
        "    printf(\"Max Texture 2D Size: [%d, %d]\\n\", deviceProp.maxTexture2D[0], deviceProp.maxTexture2D[1]);\n",
        "    printf(\"Concurrent Kernels: %s\\n\", deviceProp.concurrentKernels ? \"Supported\" : \"Not Supported\");\n",
        "    printf(\"ECC Memory: %s\\n\", deviceProp.ECCEnabled ? \"Enabled\" : \"Disabled\");\n",
        "\n",
        "    // Cache information\n",
        "    printf(\"\\nCache Configuration:\\n\");\n",
        "    printf(\"L2 Cache Size: %.2f KB\\n\", bytesToKB(deviceProp.l2CacheSize));\n",
        "    printf(\"Global Memory Bus Width: %d bits\\n\", deviceProp.memoryBusWidth);\n",
        "    printf(\"Memory Clock Rate: %.2f GHz\\n\", deviceProp.memoryClockRate / 1e6f);\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    for (int i = 0; i < deviceCount; ++i) {\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, i);\n",
        "\n",
        "        printf(\"Device %d\\n\", i);\n",
        "        displayGPUProperties(deviceProp);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3wEKuMUpseV",
        "outputId": "444234b3-1011-45ee-b632-abd55cd5a798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ8SIcnApVrh",
        "outputId": "40224ed6-7a20-4c84-a6a4-e17c25446f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MultiCore/cuda\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/MultiCore/cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoQRN7KOhBja"
      },
      "source": [
        "# Run N_Body Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WDO9fXpwlq-M"
      },
      "outputs": [],
      "source": [
        "!nvcc -o nbody_cuda n_body_cuda.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./nbody_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUWLA66QoweW",
        "outputId": "52db08d9-1e2c-4505-fe1b-403a94fdaa83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken by CUDA implementation: 17626.130838 ms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}